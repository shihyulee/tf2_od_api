{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acoustic-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "engaging-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"myproject\"\n",
    "project_name = \"Project_od_1\"\n",
    "dataset_name = \"dataset\"\n",
    "label_name = \"labels.names\"\n",
    "output_folder = \"tf_training\"\n",
    "\n",
    "num_classes = 2\n",
    "num_steps = 2000\n",
    "batch_size = 1\n",
    "\n",
    "#  \"resnet50\",  \"resnet101\", \"inception_resnet_v2\"\n",
    "NN_architecture = \"resnet101\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spare-forward",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myproject/Project_od_1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_folder = os.path.join(project_dir, project_name)\n",
    "project_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-austria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myproject/Project_od_1/dataset'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.path.join(project_folder, dataset_name)\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "short-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myproject/Project_od_1/dataset/labels.names'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_path = os.path.join(dataset_path, label_name)\n",
    "label_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "improving-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myproject/Project_od_1/tf_training\n"
     ]
    }
   ],
   "source": [
    "output_folder_path =  os.path.join(project_folder, output_folder)\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "print(output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-promise",
   "metadata": {},
   "source": [
    "## Create Label Map (pbtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reliable-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classes(classes, start=1):\n",
    "    msg = ''\n",
    "    for id, name in enumerate(classes, start=start):\n",
    "        msg = msg + \"item {\\n\"\n",
    "        msg = msg + \" id: \" + str(id) + \"\\n\"\n",
    "        msg = msg + \" name: '\" + name + \"'\\n}\\n\\n\"\n",
    "    return msg[:-1]\n",
    "\n",
    "def create_label_pbtxt(label_path, output_folder_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        data_list = f.read().splitlines()\n",
    "    \n",
    "    label_pbtxt_path = os.path.join(output_folder_path, \"label_map.pbtxt\")\n",
    "    label_map = convert_classes(data_list)\n",
    "    with open( label_pbtxt_path, \"w\") as f:\n",
    "        f.write(label_map)\n",
    "        f.close()    \n",
    "    print(\"Create 'label_map.pbtxt' Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wound-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create 'label_map.pbtxt' Done\n"
     ]
    }
   ],
   "source": [
    "create_label_pbtxt(label_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-variety",
   "metadata": {},
   "source": [
    "##  Creating TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tight-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraraies\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "import tensorflow.compat.v1 as tf\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "equal-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder name for the source annotated XML files and folder #to store the TFRecord Record file\n",
    "# LABEL_MAP_FILE=r'myproject/Project_od_1/tf_training/label_map.pbtxt'\n",
    "# TRAIN_XML_FILE=r'myproject/Project_od_1/dataset/Train'\n",
    "# TRAIN_TF_RECORD_DIR=r'myproject/Project_od_1/tf_training/train.record'\n",
    "# TEST_XML_FILE=r'myproject/Project_od_1/dataset/eval'\n",
    "# TEST_TF_RECORD_DIR=r'myproject/Project_od_1/tf_training/test.record'\n",
    "\n",
    "LABEL_MAP_FILE = os.path.join(output_folder_path, \"label_map.pbtxt\")\n",
    "TRAIN_XML_FILE = os.path.join(dataset_path, \"Train\")\n",
    "TRAIN_TF_RECORD_DIR = os.path.join(output_folder_path, \"train.record\")\n",
    "TEST_XML_FILE = os.path.join(dataset_path, \"eval\")\n",
    "TEST_TF_RECORD_DIR = os.path.join(output_folder_path, \"test.record\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "velvet-imaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myproject/Project_od_1/tf_training/train.record'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_TF_RECORD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cosmetic-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_train = \"python myproject/generate_tfrecord.py -x {} -l {} -o {}\".format(TRAIN_XML_FILE, LABEL_MAP_FILE, TRAIN_TF_RECORD_DIR)\n",
    "tfrecord_test = \"python myproject/generate_tfrecord.py -x {} -l {} -o {}\".format(TEST_XML_FILE, LABEL_MAP_FILE, TEST_TF_RECORD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "auburn-drama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(tfrecord_train)\n",
    "os.system(tfrecord_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-membrane",
   "metadata": {},
   "source": [
    "## Create config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "falling-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "from object_detection.protos import pipeline_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "human-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline_pb2.TrainEvalPipelineConfig()     \n",
    "with tf.io.gfile.GFile('myproject/sample_config/faster_rcnn_sample.config', \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "catholic-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_dict = {\n",
    "    \"resnet50\" : \"faster_rcnn_resnet50_keras\",\n",
    "    \"resnet101\" : \"faster_rcnn_resnet101_keras\",\n",
    "    \"inception_resnet_v2\" : \"faster_rcnn_inception_resnet_v2_keras\"\n",
    "}\n",
    "\n",
    "feature_extractor_dict = feature_extractor_dict[NN_architecture]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "royal-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.model.faster_rcnn.num_classes = num_classes\n",
    "pipeline.model.faster_rcnn.feature_extractor.type = feature_extractor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "liked-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.train_input_reader.label_map_path = LABEL_MAP_FILE\n",
    "pipeline.train_input_reader.tf_record_input_reader.input_path[0] = TRAIN_TF_RECORD_DIR\n",
    "\n",
    "pipeline.eval_input_reader[0].label_map_path = LABEL_MAP_FILE\n",
    "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[0] = TEST_TF_RECORD_DIR\n",
    "\n",
    "pipeline.train_config.num_steps = num_steps\n",
    "pipeline.train_config.batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "orange-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myproject/Project_od_1/tf_training/pipeline.config'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_output = os.path.join(output_folder_path, \"pipeline.config\")\n",
    "config_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ancient-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(config_output, \"wb\") as f:                                                                                                                                                                                                                       \n",
    "        f.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceramic-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(output_folder_path, \"train\")\n",
    "train_script = \"\"\"\n",
    "python object_detection/model_main_tf2.py \\\n",
    "  --model_dir={} \\\n",
    "  --pipeline_config_path={} \\\n",
    "  --alsologtostderr\n",
    "\"\"\".format(MODEL_DIR, config_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "qualified-mills",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npython object_detection/model_main_tf2.py   --model_dir=myproject/Project_od_1/tf_training/train   --pipeline_config_path=myproject/Project_od_1/tf_training/pipeline.config   --alsologtostderr\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "respected-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python-headless==4.2.0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "described-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aging-reference",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0307 13:23:32.443389 139906522142528 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0307 13:23:32.446588 139906522142528 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0307 13:23:32.446658 139906522142528 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0307 13:23:32.552999 139906522142528 deprecation.py:339] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['myproject/Project_od_1/tf_training/train.record']\n",
      "I0307 13:23:32.554981 139906522142528 dataset_builder.py:163] Reading unweighted datasets: ['myproject/Project_od_1/tf_training/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['myproject/Project_od_1/tf_training/train.record']\n",
      "I0307 13:23:32.555074 139906522142528 dataset_builder.py:80] Reading record datasets for input file: ['myproject/Project_od_1/tf_training/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0307 13:23:32.555124 139906522142528 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0307 13:23:32.555167 139906522142528 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0307 13:23:32.557940 139906522142528 deprecation.py:339] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0307 13:23:32.572339 139906522142528 deprecation.py:339] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0307 13:23:37.639810 139906522142528 deprecation.py:339] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0307 13:23:41.195800 139906522142528 deprecation.py:339] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0307 13:23:48.187535 139897864177408 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0307 13:23:54.417963 139897864177408 deprecation.py:537] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "W0307 13:23:54.800792 139897864177408 deprecation.py:339] From /home/tensorflow/.local/lib/python3.6/site-packages/object_detection/utils/model_util.py:57: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0307 13:23:56.226316 139897864177408 deprecation.py:339] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0307 13:23:59.626354 139897864177408 deprecation.py:537] From /home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"object_detection/model_main_tf2.py\", line 113, in <module>\r\n",
      "    tf.compat.v1.app.run()\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"object_detection/model_main_tf2.py\", line 110, in main\r\n",
      "    record_summaries=FLAGS.record_summaries)\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py\", line 644, in train_loop\r\n",
      "    loss = _dist_train_step(train_input_iter)\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n",
      "    result = self._call(*args, **kwds)\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 888, in _call\r\n",
      "    return self._stateless_fn(*args, **kwds)\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2943, in __call__\r\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1919, in _call_flat\r\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 560, in call\r\n",
      "    ctx=ctx)\r\n",
      "  File \"/home/tensorflow/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute\r\n",
      "    inputs, attrs, num_outputs)\r\n",
      "tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n",
      "  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n",
      "\t [[node model/conv1_conv/Conv2D (defined at home/tensorflow/.local/lib/python3.6/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1346) ]]\r\n",
      "\t [[Loss/BoxClassifierLoss/localization_loss_1/write_summary/summary_cond/then/_86/Loss/BoxClassifierLoss/localization_loss_1/write_summary/ReadVariableOp/_432]]\r\n",
      "  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n",
      "\t [[node model/conv1_conv/Conv2D (defined at home/tensorflow/.local/lib/python3.6/site-packages/object_detection/meta_architectures/faster_rcnn_meta_arch.py:1346) ]]\r\n",
      "0 successful operations.\r\n",
      "0 derived errors ignored. [Op:__inference__dist_train_step_32636]\r\n",
      "\r\n",
      "Errors may have originated from an input operation.\r\n",
      "Input Source operations connected to node model/conv1_conv/Conv2D:\r\n",
      " model/lambda/Pad (defined at home/tensorflow/.local/lib/python3.6/site-packages/object_detection/models/keras_models/resnet_v1.py:50)\r\n",
      "\r\n",
      "Input Source operations connected to node model/conv1_conv/Conv2D:\r\n",
      " model/lambda/Pad (defined at home/tensorflow/.local/lib/python3.6/site-packages/object_detection/models/keras_models/resnet_v1.py:50)\r\n",
      "\r\n",
      "Function call stack:\r\n",
      "_dist_train_step -> _dist_train_step\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/model_main_tf2.py   --model_dir=myproject/Project_od_1/tf_training/train   --pipeline_config_path=myproject/Project_od_1/tf_training/pipeline.config   --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "grateful-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def solve_cudnn_error():\n",
    "#     gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#     if gpus:\n",
    "#         try:\n",
    "#             # Currently, memory growth needs to be the same across GPUs\n",
    "#             for gpu in gpus:\n",
    "#                 tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#             logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#             print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#         except RuntimeError as e:\n",
    "#             # Memory growth must be set before GPUs have been initialized\n",
    "#             print(e)\n",
    "\n",
    "# solve_cudnn_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-cartoon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "harmful-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_name = tf.test.gpu_device_name()\n",
    "# print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "express-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "twelve-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "geographic-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-treasure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
